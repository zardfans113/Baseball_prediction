import pandas as pd
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# è¨­å®šæ—¥æ–‡å­—é«”ï¼ˆä½¿ç”¨ MS Gothicã€Yu Gothicã€Meiryo æˆ– Noto Sans CJK JPï¼‰
plt.rcParams['font.sans-serif'] = ['MS Gothic']  # æˆ– 'Meiryo', 'Yu Gothic', 'Noto Sans CJK JP'
plt.rcParams['axes.unicode_minus'] = False  # é¿å…è² è™Ÿé¡¯ç¤ºéŒ¯èª¤


# ============ ğŸ“Œ Step 1: è®€å–ä¸¦æ•´ç†æ•¸æ“š ============

file_paths = {
    "2021": "2021_qualified_hitters.csv",
    "2022": "2022_qualified_hitters.csv",
    "2023": "2023_qualified_hitters.csv",
    "2024": "2024_qualified_hitters.csv"
}

dfs = []
for year, path in file_paths.items():
    df = pd.read_csv(path)
    df["year"] = int(year)  # æ·»åŠ å¹´ä»½æ¨™è¨˜
    dfs.append(df)

df_all = pd.concat(dfs, ignore_index=True)

# æ¸…ç†æ•¸æ“šï¼šç§»é™¤é¸æ‰‹åå‰çš„æ•¸å­—æ¨™è¨˜
df_all["é¸æ‰‹å"] = df_all["é¸æ‰‹å"].str.split(":").str[-1]

# è½‰æ›æ•¸æ“šé¡å‹
float_cols = ["æ‰“ ç‡", "å‡º å¡ ç‡", "é•· æ‰“ ç‡", "O P S"]
int_cols = ["æœ¬ å¡ æ‰“", "æ‰“ ç‚¹"]

for col in float_cols:
    df_all[col] = pd.to_numeric(df_all[col], errors='coerce')
for col in int_cols:
    df_all[col] = pd.to_numeric(df_all[col], errors='coerce').fillna(0).astype(int)  # ç¢ºä¿ç‚ºæ•´æ•¸

# é¸æ“‡ç‰¹å¾µèˆ‡ç›®æ¨™è®Šæ•¸
features = ["æ‰“ å¸­ æ•°", "æ‰“ ç‡", "æœ¬ å¡ æ‰“", "å‡º å¡ ç‡", "O P S"]
targets = ["æ‰“ ç‡", "æœ¬ å¡ æ‰“", "æ‰“ ç‚¹", "å‡º å¡ ç‡", "é•· æ‰“ ç‡", "O P S"]

df_cleaned = df_all.dropna(subset=features + targets)

# ============ ğŸ“Œ Step 2: è¨“ç·´ XGBoost å’Œéš¨æ©Ÿæ£®æ—ä¾†é æ¸¬ 2024 ============

# ä½¿ç”¨ 2021-2023 è¨“ç·´ï¼Œ2024 æ¸¬è©¦
train_df = df_cleaned[df_cleaned["year"] < 2024]
test_df = df_cleaned[df_cleaned["year"] == 2024]

X_train = train_df[features]
X_test = test_df[features]

# è¨“ç·´ä¸¦é æ¸¬å¤šå€‹ç›®æ¨™è®Šæ•¸
predictions_xgb = {}
predictions_rf = {}
mae_scores_xgb = {}
mae_scores_rf = {}
mse_scores_xgb = {}
mse_scores_rf = {}
r2_scores_xgb = {}
r2_scores_rf = {}

df_2024_predictions_xgb = pd.DataFrame()
df_2024_predictions_rf = pd.DataFrame()

df_2024_predictions_xgb["é¸æ‰‹å"] = test_df["é¸æ‰‹å"]
df_2024_predictions_xgb["çƒ å›£"] = test_df["çƒ å›£"]
df_2024_predictions_rf["é¸æ‰‹å"] = test_df["é¸æ‰‹å"]
df_2024_predictions_rf["çƒ å›£"] = test_df["çƒ å›£"]

for target in targets:
    # **XGBoost æ¨¡å‹**
    xgb_model = xgb.XGBRegressor(
        objective='reg:squarederror',
        n_estimators=10000,
        learning_rate=0.001,
        max_depth=8,
        subsample=0.9,
        colsample_bytree=0.7
    )
    y_train = train_df[target]
    y_test = test_df[target]
    
    xgb_model.fit(X_train, y_train)
    y_pred_xgb = xgb_model.predict(X_test)
    
    predictions_xgb[target] = y_pred_xgb
    mae_scores_xgb[target] = mean_absolute_error(y_test, y_pred_xgb)
    mse_scores_xgb[target] = mean_squared_error(y_test, y_pred_xgb)
    r2_scores_xgb[target] = r2_score(y_test, y_pred_xgb)
    
    df_2024_predictions_xgb[f"{target}"] = y_pred_xgb
    
    # **éš¨æ©Ÿæ£®æ—æ¨¡å‹**
    rf_model = RandomForestRegressor(
        n_estimators=250,  
        max_depth=10,
        random_state=42
    )
    rf_model.fit(X_train, y_train)
    y_pred_rf = rf_model.predict(X_test)
    
    predictions_rf[target] = y_pred_rf
    mae_scores_rf[target] = mean_absolute_error(y_test, y_pred_rf)
    mse_scores_rf[target] = mean_squared_error(y_test, y_pred_rf)
    r2_scores_rf[target] = r2_score(y_test, y_pred_rf)
    
    df_2024_predictions_rf[f"{target}"] = y_pred_rf

    print(f"ğŸ”¹ {target} - XGBoost MAE: {mae_scores_xgb[target]:.4f} | Random Forest MAE: {mae_scores_rf[target]:.4f}")
    print(f"   â†³ XGBoost MSE: {mse_scores_xgb[target]:.4f} | Random Forest MSE: {mse_scores_rf[target]:.4f}")
    print(f"   â†³ XGBoost RÂ²: {r2_scores_xgb[target]:.4f} | Random Forest RÂ²: {r2_scores_rf[target]:.4f}")

# ============ ğŸ“Œ Step 3: è¦–è¦ºåŒ–æ¯”è¼ƒ ============

plt.figure(figsize=(10, 6))
x_labels = targets
x = np.arange(len(x_labels))

plt.bar(x - 0.2, mae_scores_xgb.values(), width=0.4, label="XGBoost", color="blue")
plt.bar(x + 0.2, mae_scores_rf.values(), width=0.4, label="Random Forest", color="green")
plt.xticks(x, x_labels, rotation=45)
plt.ylabel("Mean Absolute Error (MAE)")
plt.title("XGBoost vs. Random Forest MAE æ¯”è¼ƒ")
plt.legend()
plt.show()

# **èª¤å·®åˆ†ä½ˆæ•£é»åœ–**
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()

for i, target in enumerate(targets):
    ax = axes[i]
    ax.scatter(test_df[target], predictions_xgb[target], label="XGBoost", alpha=0.6, color="blue")
    ax.scatter(test_df[target], predictions_rf[target], label="Random Forest", alpha=0.6, color="green")
    ax.plot([min(test_df[target]), max(test_df[target])], [min(test_df[target]), max(test_df[target])], color="red", linestyle="dashed")
    ax.set_xlabel("Actual")
    ax.set_ylabel("Predicted")
    ax.set_title(target)
    ax.legend()

plt.tight_layout()
plt.show()
# ============ ğŸ“Œ Step 3: ä½¿ç”¨ 2021-2024 è¨“ç·´ä¸¦é æ¸¬ 2025 ============

train_df_2025 = df_cleaned[df_cleaned["year"] <= 2024]  # **ä½¿ç”¨ 2021-2024 è¨“ç·´**
X_train_2025 = train_df_2025[features]

# **ğŸš€ èª¿æ•´ 2021-2024 çš„æ•¸æ“šæ¬Šé‡**
train_df_2025["weight"] = train_df_2025["year"].map({
    2021: 0.5,  
    2022: 1.0,
    2023: 1.5,  
    2024: 2.0
})

df_2025_predictions_xgb = pd.DataFrame()
df_2025_predictions_rf = pd.DataFrame()

df_2025_predictions_xgb["é¸æ‰‹å"] = df_2024_predictions_xgb["é¸æ‰‹å"]
df_2025_predictions_xgb["çƒ å›£"] = df_2024_predictions_xgb["çƒ å›£"]
df_2025_predictions_rf["é¸æ‰‹å"] = df_2024_predictions_rf["é¸æ‰‹å"]
df_2025_predictions_rf["çƒ å›£"] = df_2024_predictions_rf["çƒ å›£"]

# **å‰µå»º 2025 æ¸¬è©¦æ•¸æ“š**
X_test_2025 = X_test.copy()
X_test_2025 += X_test_2025 * np.random.uniform(-0.05, 0.05, X_test_2025.shape)  # **æ¨¡æ“¬ 2025 çš„è®ŠåŒ–**

for target in targets:
    y_train_2025 = train_df_2025[target]

    # **XGBoost**
    xgb_model.fit(X_train_2025, y_train_2025, sample_weight=train_df_2025["weight"])
    df_2025_predictions_xgb[target] = xgb_model.predict(X_test_2025)

    # **éš¨æ©Ÿæ£®æ—**
    rf_model.fit(X_train_2025, y_train_2025, sample_weight=train_df_2025["weight"])
    df_2025_predictions_rf[target] = rf_model.predict(X_test_2025)

# ç¢ºä¿ "æœ¬å¡æ‰“" å’Œ "æ‰“ç‚¹" ç‚ºæ•´æ•¸
for target in ["æœ¬ å¡ æ‰“", "æ‰“ ç‚¹"]:
    df_2025_predictions_xgb[target] = df_2025_predictions_xgb[target].round().astype(int)
    df_2025_predictions_rf[target] = df_2025_predictions_rf[target].round().astype(int)

# å„²å­˜é æ¸¬çµæœ
df_2025_predictions_xgb.to_csv("2025_predicted_stats_xgb.csv", index=False, encoding='utf-8-sig')
df_2025_predictions_rf.to_csv("2025_predicted_stats_rf.csv", index=False, encoding='utf-8-sig')

print("âœ… 2025 å¹´é æ¸¬å·²å®Œæˆï¼Œçµæœå­˜ç‚º 2025_predicted_stats_xgb.csv å’Œ 2025_predicted_stats_rf.csv")